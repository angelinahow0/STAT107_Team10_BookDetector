percy4_text <- read_file("Percy Jackson 4.txt")
percy4_clean <- percy4_text %>%
tolower() %>%
replace_non_ascii() %>%
str_replace_all("[■©:.!?”“—(),;’‘_]", " ") %>%
str_replace_all("[0-9]", "") %>%
str_squish()
percy5_text <- read_file("Percy Jackson 5.txt")
percy5_clean <- percy5_text %>%
tolower() %>%
replace_non_ascii() %>%
str_replace_all("[■©:.!?”“—(),;’‘_]", " ") %>%
str_replace_all("[0-9]", "") %>%
str_squish()
#instead of file, out it in a list so it will be easier when we try to identify book by sentence
books_fulltext <- list(
HarryPotter = hp_clean,
Percy1 = percy1_clean,
Percy2 = percy2_clean,
Percy3 = percy3_clean,
Percy4 = percy4_clean,
Percy5 = percy5_clean
)
combined_books <- tibble(
book = names(books_fulltext),
text = unlist(books_fulltext)
)
#save those into one file
save(combined_books, file = "12_DataSaving.RData")
head(combined_books)
View(books_fulltext)
View(books_fulltext)
?ggplot()
source("00_requirements.R")
load("12_DataSaving.RData")
ggplot(combined_books)
source("00_requirements.R")
load("12_DataSaving.RData")
ggplot(combined_books)
source("00_requirements.R")
load("12_DataSaving.RData")
ggplot(data = combined_books)
source("00_requirements.R")
load("12_DataSaving.RData")
text_words <- unlist(str_split(combined_books$text, " "))
text_table <- table(combined_books$text)
paste0("No. of different words: ", length(text_table))  # how many unique words?
min(text_table)     # minimum count
names(text_table)[which.min(text_table)]
max(text_table)     # maximum count
names(text_table)[which.max(text_table)]
# ggplot(data = combined_books, mapping = aes(word, ))
knitr::opts_chunk$set(echo = TRUE)
if (!require(stringr)) {
install.packages("stringr")
library(stringr)
}
# read the text and strip away whitespace; select the non-empty lines
the_text <- readLines("janeeyre.txt")
the_text[1:30]
length(the_text)
the_text <- str_trim(the_text)
the_text[1:30]
the_text <- the_text[ nchar(the_text) > 0 ]
the_text[1:30]
# make a single string (small example)
cat(str_flatten(the_text[1:20], collapse = " "))
# make a single string
text_string <- str_flatten(the_text, collapse = " ")
# simplify by making everything lower case
text_string <- str_to_lower(text_string)
# find the start of Chapter XXVII
str_locate_all(text_string, pattern = "chapter xxvii") ## make sure it appears in the right place.
idx_start <- str_locate(text_string, fixed("chapter xxvii"))
idx_start <- unname(idx_start[, "end"]) + 1
# find the start of Chapter XXVIII
idx_end <- str_locate(text_string, fixed("chapter xxviii"))
idx_end <- unname(idx_end[, "start"]) - 1
# select the main text
text_main <- str_sub(text_string, idx_start, idx_end)
# eliminate punctuation (uses regular expression)
text_main <- str_replace_all(text_main, "[:.!?”“—(),;’‘_]", "")
# eliminate numbers -- (regular expression)
text_main <- str_replace_all(text_main, "[0-9]", "")
str_sub(text_main, 1, 2000)
text_words <- unlist(str_split(text_main, " "))
text_table <- table(text_words)
paste0("No. of different words: ", length(text_table))  # how many unique words?
min(text_table)     # minimum count
names(text_table)[which.min(text_table)]
max(text_table)     # maximum count
names(text_table)[which.max(text_table)]
text_table <- table(text_words)
cat("Total Number of words in chapter: ", length(text_words), "\n")
cat("Total Number of different words: " ,dim(text_table),"\n\n")
## Top 20 words:
cat("\n\n \bTop 20 words:   \n")
sort(text_table, decreasing = TRUE)[1:30]
## Bottom 20 words:
cat("\n\n \bBottom 20 words:   \n")
sort(text_table, decreasing = FALSE)[1:30]
library(wordcloud)
wordcloud(names(text_table), unname(text_table), min.freq = 10)
if (!require(tm)) {
install.packages("tm")
library(tm)
}
## Remove non-stop words.
text_main_tm <- Corpus(VectorSource(text_main))
text_main_nonstop <- tm_map(text_main_tm, removeWords, stopwords("english"))
## Process result.
text_words_nonstop <- str_split(text_main_nonstop[[1]]$content, pattern = " ")[[1]]
text_words_nonstop <- text_words_nonstop[nchar(text_words_nonstop) > 0]
text_table_nonstop <- table(text_words_nonstop)
cat("Total Number of words in chapter: ", length(text_words_nonstop), "\n")
cat("Total Number of stopwords in chapter: ",
length(text_words) - length(text_words_nonstop), "\n")
cat("Total Number of different words: " ,dim(text_table),"\n\n")
## Top 20 words:
cat("\n\n \bTop 20 words without stopwords:   \n")
sort(text_table_nonstop, decreasing = TRUE)[1:30]
## Bottom 20 words:
cat("\n\n \bBottom 20 words without stopwords:   \n")
sort(text_table_nonstop, decreasing = FALSE)[1:30]
sort(text_table_nonstop, decreasing = TRUE)
library(wordcloud)
wordcloud(names(text_table_nonstop), unname(text_table_nonstop), min.freq = 8)
hist(text_table_nonstop, breaks = 60,
main = "Word Frequency distribution",
xlab = "Word Frequency",
ylab = "Counts of Word Frequency")
# read the text and strip away whitespace; select the non-empty lines
the_text_raw <- readLines("janeeyre.txt")
the_text_temp1 <- str_trim(the_text_raw)
the_text <- the_text_temp1[ sapply(the_text_temp1, nchar) > 0 ]
# make a single string
text_string <- str_flatten(the_text, collapse = " ")
cat(substr(text_string, 1, 2000))
the_text <- str_trim(readLines("janeeyre.txt")[1:1000])[ sapply(str_trim(readLines("janeeyre.txt")[1:1000]), nchar) > 0 ]
cat(substr(str_flatten(the_text, collapse = " "), 1, 2000))
if (!require(magrittr)) {
install.packages("magrittr")
library(magrittr)
}
pokemon <- read.csv("Pokemon.csv")
pokemon_reduced <- head(pokemon, 10)
pokemon_reduced
"Pokemon.csv" %>% read.csv() %>% head(10)
## If I want to save it, I can assign it to an object:
pokemon_reduced <- "Pokemon.csv" %>% read.csv() %>% head(10)
the_text <- "janeeyre.txt" %>%
readLines() %>%
str_trim() %>%
str_flatten() %>%
substr(1, 2000)
cat(the_text)
the_text <- "janeeyre.txt" %>%
readLines() %>%
str_trim() %>%
str_flatten() %>%
substr(1, 2000) %>%
cat()
cat(paste("\n The output of the operations is:\n"))
print(the_text)
## Nothing, because the cat() function returns no output...
the_text <- "janeeyre.txt" %>%
readLines() %>%
str_trim() %>%
str_flatten() %>%
substr(1, 2000) %T>% ## Adding tee pipe operator...
cat()
cat(paste("\n_\n_\n  The output of the operations is:\n_\n_\n "))
cat(the_text)
the_text <- "janeeyre.txt" %>%
readLines() %>%
str_trim() %>%
str_flatten() %>%
str_to_lower()
## Beggining of chapter 20
idx_start <- the_text %>%
str_locate(fixed("chapter xx")) %>%
unname() %>%
max() %>%
add(1)
## End of chapter 30
idx_end <- the_text %>%
str_locate(fixed("chapter xxxi")) %>%
unname()  %>%
min() %>%
add(-1)
## cleaning and saving only chapter 10:
text_main <- the_text %>%
str_sub(idx_start, idx_end) %>%
str_replace_all("[:.!?”“—(),;’‘_]", "") %>%
str_replace_all("[0-9]", "")
## Text_nonstop
text_main_nonstop <- text_main %>%
VectorSource() %>% Corpus() %>%
tm_map(removeWords, stopwords("english")) %>%
{.[[1]]$content} %>%
{str_split(., pattern = " ")[[1]]} %>%
{.[nchar(.)> 0]}
## Sorted table with word frequencies
text_table_nonstop <- text_main_nonstop %>%
strsplit(" ") %>%
unlist() %>%
table() %>%
sort(decreasing = TRUE)
wordcloud(names(text_table_nonstop), unname(text_table_nonstop), max.words = 80)
the_text2 <- "harrypotter1.txt" %>%
readLines() %>%
str_trim() %>%
str_flatten(collapse = " ") %>%
str_to_lower()
## Beggining of chapter 1
idx_start2 <- the_text2 %>%
str_locate(fixed("chapter one")) %>%
unname() %>%
max() %>%
add(1)
## End of chapter 11
idx_end2 <- the_text2 %>%
str_locate(fixed("chapter eleven")) %>%
unname()  %>%
min() %>%
add(-1)
## cleaning and saving only chapters 1-11
text_main2 <- the_text2 %>%
str_sub(idx_start2, idx_end2) %>%
str_replace_all("[:.!?”“—(),;’‘_\"]", " ") %>%
str_replace_all("--", " ") %>%
str_replace_all("[0-9]", " ")
## Text_nonstop
text_main_nonstop2 <- text_main2 %>%
VectorSource() %>% Corpus() %>%
tm_map(removeWords, stopwords("english")) %>%
{.[[1]]$content} %>%
{str_split(., pattern = " ")[[1]]} %>%
{.[nchar(.)> 0]}
## Sorted table with word frequencies
text_table_nonstop2 <- text_main_nonstop2 %>%
strsplit(" ") %>%
unlist() %>%
table() %>%
sort(decreasing = TRUE)
par(mar = c(0,0,0,0))
wordcloud(names(text_table_nonstop), unname(text_table_nonstop), max.words = 80)
wordcloud(names(text_table_nonstop2), unname(text_table_nonstop2), max.words = 80)
cat("Jane Eyre: \n")
cat("Total Number of non-stopwords in chapter: ", sum(text_table_nonstop), "\n")
cat("Total Number of different non-stopwords: " ,dim(text_table_nonstop),"\n\n\n")
cat("Harry Potter 1: \n")
cat("Total Number of non-stopwords in chapter: ", sum(text_table_nonstop2), "\n")
cat("Total Number of different non-stopwords: " ,dim(text_table_nonstop2),"\n\n\n")
OH <- read.csv("OH_responses.csv")
dim(OH)
colnames(OH) <- c("timestamp", "responses")
View(OH)
# empty data frame
survey <- data.frame(matrix(nrow = 0, ncol = 13))
# set the column names
colnames(survey) <- c(
"timestamp",
"Tues10", "Tues11", "Tues12", "Tues13", "Tues14", "Tues15",
"Thur10", "Thur11", "Thur12", "Thur13", "Thur14", "Thur15"
)
# specify the labels for each option
options <- c(
"Tuesday - 10:00AM - 11:00AM",
"Tuesday - 11:00AM - 12:00PM",
"Tuesday - 12:00PM - 1:00PM",
"Tuesday - 1:00PM - 2:00PM",
"Tuesday - 2:00PM - 3:00PM",
"Tuesday - 3:00PM - 4:00PM",
"Thursday - 10:00AM - 11:00AM",
"Thursday - 11:00AM - 12:00PM",
"Thursday - 12:00PM - 1:00PM",
"Thursday - 1:00PM - 2:00PM",
"Thursday - 2:00PM - 3:00PM",
"Thursday - 3:00PM - 4:00PM"
)
clean_responses <- function(old_response) {
new_format <- str_replace_all(pattern = "day,", replacement = "day -", string = old_response)
new_response_list <- str_split(new_format, pattern = ", ")
new_response <- unlist(new_response_list)
# return the cleaned data
return(new_response)
}
my_test1 <- clean_responses("Tuesday, 10:00AM - 11:00AM")
my_test1
my_test2 <- clean_responses("Tuesday, 10:00AM - 11:00AM, Tuesday, 11:00AM - 12:00PM")
my_test2
length(my_test2)
## Option 1:
for (i in 1:nrow(OH)) {
## Extract values:
t_stamp <- OH$timestamp[i]
student_options <- OH$responses[i]
new_responses <- clean_responses(student_options)
## New row: list.
new_row <- list(timestamp = t_stamp)
for (ind in 1:length(options)) {
is_option_in <- options[ind] %in% new_responses
new_row[[ind + 1]] <- is_option_in
}
survey[i,] <- new_row
}
View(survey)
library(plot.matrix)
plot(as.matrix(survey[,-1]))
pokemon <- read_csv("Pokemon.csv")
## Numeric:
ggplot(pokemon, aes(x = Attack))
ggplot(pokemon, aes(y = Defense))
ggplot(pokemon, aes(x = Attack, y = Defense))
## Factor:
ggplot(pokemon, aes(x = factor(Generation)))
ggplot(pokemon, aes(y = Type1))
ggplot(pokemon, aes(x = factor(Generation), y = Type1))
##        part 1: variables to plot           + part 2: what to plot.
ggplot(pokemon, aes(x = Attack, y = Defense)) + geom_point()
## Single color:
ggplot(pokemon, aes(x = Attack, y = Defense)) + geom_point()
ggplot(pokemon, aes(x = Attack, y = Defense)) + geom_point(col = "red")
## Coloring by Legendary pokemon status.
ggplot(pokemon, aes(x = Attack, y = Defense)) + geom_point(aes(col = Legendary))
## Change point size for all points:
ggplot(pokemon, aes(x = Attack, y = Defense)) + geom_point()
ggplot(pokemon, aes(x = Attack, y = Defense)) + geom_point(size = 3)
## Point size according to variable
pokemon_1 <- pokemon[pokemon$Generation == 1, ]
ggplot(pokemon_1, aes(x = Attack, y = Defense)) + geom_point(aes(col = Legendary, size = HP))
## For numerical variables! Add a factor to plot "grouped by":
## Plotting a single boxplot.
ggplot(pokemon, aes(x = Attack)) + geom_boxplot()
ggplot(pokemon, aes(y = Defense)) + geom_boxplot()
## We can create grouped boxplots by adding a factor variable:
ggplot(pokemon, aes(x = Type1, y = Attack)) + geom_boxplot()
ggplot(pokemon, aes(x = Attack, y = Type1)) + geom_boxplot() + geom_point(aes(col = Legendary))
## For categorical variables! Counts:
##  part 1: variable to plot     + part 2: what to plot.
ggplot(pokemon, aes(x = Generation)) + geom_bar()
ggplot(pokemon, aes(y = Generation)) + geom_bar()
## Adding color to represent more variables:
ggplot(pokemon, aes(y = Generation)) + geom_bar(aes(col = Legendary))
## Single density:
ggplot(pokemon, aes(x = Attack)) + geom_density()
## Multiple densities with colors:
ggplot(pokemon, aes(x = Total)) + geom_density(aes(col = factor(Legendary)))
ggplot(pokemon, aes(x = Total)) + geom_density(aes(col = factor(Generation)))
## Comparing a density vs. violin plot:
ggplot(pokemon, aes(x = Total, col = Legendary)) + geom_density()
ggplot(pokemon, aes(x = Total, y = Legendary)) + geom_violin()
## Another example
ggplot(pokemon, aes(x = Total)) + geom_density(aes(col = factor(Generation)))
ggplot(pokemon, aes(x = Total, y = factor(Generation))) + geom_violin(aes(col = factor(Generation)))
## We know how the joint plot of Attack vs Defense look:
ggplot(pokemon, aes(x = Attack, y = Defense)) +
geom_point()
## Joint distribution density:
ggplot(pokemon, aes(x = Attack, y = Defense)) + geom_density_2d()
ggplot(pokemon, aes(x = Attack, y = Defense)) + geom_density_2d_filled()
## Joint distribution separated by Legendary/non-Legendary:
ggplot(pokemon, aes(x = Attack, y = Defense)) + geom_density_2d(aes(col = Legendary))
## Joint distribution separated by Legendary/non-Legendary:
ggplot(pokemon, aes(x = Attack, y = Defense)) +
geom_point(aes(col = Legendary)) +
geom_density_2d()
ggplot(pokemon, aes(x = Attack, y = Defense)) +
geom_point(aes(col = Legendary)) +
geom_density_2d(aes(col = Legendary))
## Original plot.
ggplot(pokemon, aes(x = Attack, y = Defense)) + geom_point()
## Fixed line:
ggplot(pokemon, aes(x = Attack, y = Defense)) + geom_point() +
geom_hline(yintercept = 100)
## Line depending on variables: inside aes()
ggplot(pokemon, aes(x = Attack, y = Defense)) + geom_point() +
geom_hline(aes(yintercept = mean(Defense)), col = "red")
## Both lines:
ggplot(pokemon, aes(x = Attack, y = Defense)) + geom_point() +
geom_hline(aes(yintercept = mean(Defense)), col = "red") +
geom_vline(aes(xintercept = mean(Attack)), col = "blue")
coef <- lm(Defense ~ Attack, data = pokemon)$coefficients
print(coef)
## Both lines:
ggplot(pokemon, aes(x = Attack, y = Defense)) + geom_point() +
geom_hline(aes(yintercept = mean(Defense)), col = "red") +
geom_vline(aes(xintercept = mean(Attack)), col = "blue") +
geom_abline(intercept = coef[1], slope = coef[2], col = "darkgreen")
ggplot(pokemon, aes(x = Attack, y = Defense)) + geom_point() +
xlim(0, 300) + ylim(0, 500) +
xlab("Pokemon Attack!") +
ylab("Pokemon Defense!") +
labs(title = "Example Plot", subtitle = "Attack vs. Defense")
ggplot(pokemon, aes(x = Attack, y = Defense)) +
geom_point(aes(col = Legendary, shape = Legendary), size = 2)
ggplot(pokemon, aes(x = Total)) +
geom_density(aes(col = factor(Legendary), linetype = factor(Legendary)))
ggplot(pokemon, aes(x = Total)) +
geom_density(aes(col = factor(Generation), linetype = factor(Generation)))
ggplot(pokemon, aes(x = Total)) +
geom_density(aes(col = factor(Generation), linetype = factor(Legendary)))
ggplot(pokemon, aes(x = Total)) +
geom_density(aes(col = factor(Generation))) +
facet_grid(cols = vars(Legendary))
ggplot(pokemon, aes(x = Total)) +
geom_density(aes(col = factor(Generation))) +
facet_grid(rows = vars(Legendary),
cols = vars(Generation))
ggplot(pokemon, aes(x = Total)) +
geom_density(aes(col = Legendary)) +
facet_grid(cols = vars(Generation))
ggplot(pokemon, aes(x = Attack, y = Defense)) +
geom_point() + geom_density2d_filled() +
facet_grid(cols = vars(Generation))
ggplot(pokemon, aes(x = Attack, y = Defense)) +
geom_point() + geom_density2d_filled() +
facet_grid(cols = vars(Legendary))
q()
source("00_requirements.R")
load("12_DataSaving.RData")
combined_books <- combined_books %>%
mutate(series = ifelse(str_detect(book, "percyjackson"), "Percy Jackson", "Harry Potter"))
book_words <- combined_books %>%
unnest_tokens(word, text)
series_counts <- book_words %>%
count(series, word, sort = TRUE)
top_series_words <- series_counts %>%
group_by(series) %>%
slice_max(n, n = 10) %>%
ungroup()
ggplot(top_series_words, aes(x = reorder_within(word, n, series), y = n, fill = series)) +
geom_col(show.legend = FALSE) +
facet_wrap(~ series, scales = "free") +
scale_x_reordered() +
coord_flip() +
labs(title = "Most Common Words by Series",
x = "Word",
y = "Frequency")
View(series_counts)
View(books_fulltext)
View(book_words)
source("00_requirements.R")
load("12_DataSaving.RData")
#convert into list for using tm
books_fulltext <- setNames(as.list(combined_books$text), book_words$book)
View(combined_books)
source("00_requirements.R")
load("12_DataSaving.RData")
#convert into list for using tm
books_fulltext <- setNames(as.list(book_words$book), book_words$series)
clean_tm <- function(book_text) {
#created corpus
corpus <- VCorpus(VectorSource(book_text))
#remove the stop words
corpus <- tm_map(corpus, removeWords, stopwords("english"))
#remove extra whitespaces
corpus <- tm_map(corpus, stripWhitespace)
#words into vector
words <- str_split(corpus[[1]]$content, " ")[[1]]
#remove empty string
words <- words[nchar(words) > 0]
return(words)
}
#make the changes into all the books
books_words <- lapply(books_fulltext, clean_tm)
knitr::opts_chunk$set(echo = TRUE)
### DO NOT CHANGE THIS PIECE OF CODE.
### DO NOT CHANGE THIS PIECE OF CODE.
### DO NOT CHANGE THIS PIECE OF CODE.
if (!require(mvtnorm)) {
install.packages("mvtnorm")
library(mvtnorm)
}
if (!require(matlib)) {
install.packages("matlib")
library(matlib)
}
if (!require(scatterplot3d)) {
install.packages("scatterplot3d")
library(scatterplot3d)
}
if (!require(rgl)) {
install.packages("rgl")
library(rgl)
}
if (!require(car)) {
install.packages("car")
library(car)
}
if (!require(mgcv)) {
install.packages("mgcv")
library(mgcv)
}
if(!require(plot.matrix)) {
install.packages("plot.matrix")
library(plot.matrix)
}
if(!require(glmnet)) {
install.packages("glmnet")
library(glmnet)
}
## Colorblind friendly palette. Required to use these colors for assignments.
cbPalette <- c("#999999", "#E69F00", "#56B4E9",
"#009E73", "#F0E442", "#0072B2",
"#D55E00", "#CC79A7")
# plot(1:8, col = cbPalette)
### DO NOT CHANGE THIS PIECE OF CODE.
### DO NOT CHANGE THIS PIECE OF CODE.
### DO NOT CHANGE THIS PIECE OF CODE.
data_high <- read.csv("df_clean_high2.csv")[, 2:10]
